# Copyright (c) HashiCorp, Inc.
# SPDX-License-Identifier: MPL-2.0

"""FleetDM Vulnerability connector for Grove."""

import json
from datetime import datetime, timedelta

from grove.connectors import BaseConnector
from grove.connectors.fleetdm.api import Client
from grove.constants import REVERSE_CHRONOLOGICAL
from grove.exceptions import NotFoundException


class Connector(BaseConnector):
    NAME = "fleetdm_vulnerability_logs"
    POINTER_PATH = "date_create"
    LOG_ORDER = REVERSE_CHRONOLOGICAL

    @property
    def params(self):
        """Fetches the parameters for the API call.

        This is used to control what data should be pulled back in config files rather
        than hardcoded. This defaults to None.

        :return: The dict of params defined in the connector configuration.
        """
        try:
            p = self.configuration.params
        except AttributeError:
            return None

        return p

    def collect(self):
        """Collects all hosts from the FleetDM API.
        """
        client = Client(
            token=self.key,
            params=self.params
            )
        cursor = 0

#       We do a full load of hosts on each run as there's no good way to determine if
#       vulns have been added to the system even if the host itself has not updated since
#       last time.

#        # If no pointer is stored then a previous run hasn't been performed, so set the
#        # pointer to a week ago. In the case of the Slack audit API the pointer is the
#        # value of the "date_create" field from the latest record retrieved from the
#        # API - which is in seconds since epoch ("Unix Time") format.
        try:
            _ = self.pointer
        except NotFoundException:
            self.pointer = (datetime.utcnow() - timedelta(days=7)).strftime("%s")

        # Page over data using the cursor, saving returned data page by page.
        while True:
#            p = json.dumps(self.identity)
            log = client.get_hosts(cursor=cursor,params=self.params)
#            print(log.entries)

            # Save this batch of log entries.
            self.save(log.entries)

            # Check if we need to continue paging.
            cursor = log.cursor
            if cursor is None:
                break
